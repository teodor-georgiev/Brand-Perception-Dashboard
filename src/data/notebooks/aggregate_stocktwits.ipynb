{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "# import re\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.data/tab2/aggregated_stocks_values_days.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Programming\\Brand Perception Dashboard\\src\\data\\notebooks\\aggregate_stocktwits.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Programming/Brand%20Perception%20Dashboard/src/data/notebooks/aggregate_stocktwits.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_stocks_days \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m.data/tab2/aggregated_stocks_values_days.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Programming/Brand%20Perception%20Dashboard/src/data/notebooks/aggregate_stocktwits.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m brands_list \u001b[39m=\u001b[39m df_stocks_days[\u001b[39m\"\u001b[39m\u001b[39mBrand Name\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Programming/Brand%20Perception%20Dashboard/src/data/notebooks/aggregate_stocktwits.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m brands_list\u001b[39m.\u001b[39msort()\n",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m     f,\n\u001b[0;32m   1220\u001b[0m     mode,\n\u001b[0;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1227\u001b[0m )\n\u001b[0;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.data/tab2/aggregated_stocks_values_days.csv'"
     ]
    }
   ],
   "source": [
    "df_stocks_days = pd.read_csv(\".data/tab2/aggregated_stocks_values_days.csv\")\n",
    "brands_list = df_stocks_days[\"Brand Name\"].unique()\n",
    "brands_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Airbnb', 'Apple', 'Coca-Cola', 'HM', 'Nike', 'Pepsi', 'Starbucks'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'data\\tab2\\stocktwits' # use your path\n",
    "files = glob.glob(os.path.join(path , \"*.csv\"))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HNNMY.csv',\n",
       " 'ABNB.csv',\n",
       " 'PEP.csv',\n",
       " 'KO.csv',\n",
       " 'AAPL.csv',\n",
       " 'SBUX.csv',\n",
       " 'NKE.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands_files = [str.split(str.rsplit(i, sep=\"\\\\\", maxsplit=1)[1], sep=\"_\", maxsplit=1)[1] for i in files]\n",
    "brands = [*set(brands_files)]\n",
    "brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate = pd.DataFrame()\n",
    "for i in files:\n",
    "    df_file = pd.read_csv(i, sep=\";\")\n",
    "    df_file[\"brand\"] = str.split(str.rsplit(i, sep=\"\\\\\", maxsplit=1)[1], sep=\"_\", maxsplit=1)[1]\n",
    "    df_file[\"brand\"] = df_file[\"brand\"].str[0:-4]\n",
    "    df_aggregate = pd.concat([df_aggregate, df_file], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>trend</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>caption</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>$PLTR $AAPL what a waste of time today...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>$AAPL hoping to get above 130 by Friday! Is th...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SmartOptions® Unusual Activity Alert\\n(Delayed...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>More paper hand shake outs on no news. Vaccine...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>$AAPL AND.....this is what we call a bear trap...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11051</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>$SBUX 80 EOW</td>\n",
       "      <td>SBUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11052</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>$SBUX can’t lie, this one is a bit scary becau...</td>\n",
       "      <td>SBUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11053</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>$SBUX get ready to get punished bears 😹😹😹😹😹😹😹😹...</td>\n",
       "      <td>SBUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11054</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>$SBUX ☕️</td>\n",
       "      <td>SBUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11055</th>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Free video with setups for May 28  \"The New No...</td>\n",
       "      <td>SBUX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64401 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date    trend  replies  likes  \\\n",
       "0      2021-03-02      NaN        1      3   \n",
       "1      2021-03-02      NaN        3      2   \n",
       "2      2021-03-02  Bearish        0      0   \n",
       "3      2021-03-02  Bullish        2     12   \n",
       "4      2021-03-02      NaN        1      4   \n",
       "...           ...      ...      ...    ...   \n",
       "11051  2020-05-28      NaN        0      1   \n",
       "11052  2020-05-28      NaN        0      0   \n",
       "11053  2020-05-28  Bullish        2      4   \n",
       "11054  2020-05-28      NaN        3      4   \n",
       "11055  2020-05-27      NaN        0      1   \n",
       "\n",
       "                                                 caption brand  \n",
       "0              $PLTR $AAPL what a waste of time today...  AAPL  \n",
       "1      $AAPL hoping to get above 130 by Friday! Is th...  AAPL  \n",
       "2      SmartOptions® Unusual Activity Alert\\n(Delayed...  AAPL  \n",
       "3      More paper hand shake outs on no news. Vaccine...  AAPL  \n",
       "4      $AAPL AND.....this is what we call a bear trap...  AAPL  \n",
       "...                                                  ...   ...  \n",
       "11051                                       $SBUX 80 EOW  SBUX  \n",
       "11052  $SBUX can’t lie, this one is a bit scary becau...  SBUX  \n",
       "11053  $SBUX get ready to get punished bears 😹😹😹😹😹😹😹😹...  SBUX  \n",
       "11054                                           $SBUX ☕️  SBUX  \n",
       "11055  Free video with setups for May 28  \"The New No...  SBUX  \n",
       "\n",
       "[64401 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aggregate[\"date\"] = pd.to_datetime(df_aggregate[\"date\"])\n",
    "df_aggregate[\"date\"] = df_aggregate[\"date\"].dt.date\n",
    "df_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_abrev = df_aggregate[\"brand\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL': 'Apple',\n",
       " 'ABNB': 'Airbnb',\n",
       " 'HNNMY': 'HM',\n",
       " 'KO': 'Coca-Cola',\n",
       " 'NKE': 'Nike',\n",
       " 'PEP': 'Pepsi',\n",
       " 'SBUX': 'Starbucks'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_abrev = {'AAPL' : \"Apple\", 'ABNB' : \"Airbnb\", 'HNNMY':\"HM\", 'KO':\"Coca-Cola\", 'NKE':\"Nike\", 'PEP':\"Pepsi\", 'SBUX':\"Starbucks\"}\n",
    "brand_abrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate[\"brand\"] = df_aggregate[\"brand\"].map(brand_abrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>trend</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>caption</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>$PLTR $AAPL what a waste of time today...</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>$AAPL hoping to get above 130 by Friday! Is th...</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SmartOptions® Unusual Activity Alert\\n(Delayed...</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>More paper hand shake outs on no news. Vaccine...</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>$AAPL AND.....this is what we call a bear trap...</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11051</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>$SBUX 80 EOW</td>\n",
       "      <td>Starbucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11052</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>$SBUX can’t lie, this one is a bit scary becau...</td>\n",
       "      <td>Starbucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11053</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>$SBUX get ready to get punished bears 😹😹😹😹😹😹😹😹...</td>\n",
       "      <td>Starbucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11054</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>$SBUX ☕️</td>\n",
       "      <td>Starbucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11055</th>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Free video with setups for May 28  \"The New No...</td>\n",
       "      <td>Starbucks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64401 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  trend  replies  likes  \\\n",
       "0      2021-03-02    NaN        1      3   \n",
       "1      2021-03-02    NaN        3      2   \n",
       "2      2021-03-02    0.0        0      0   \n",
       "3      2021-03-02    1.0        2     12   \n",
       "4      2021-03-02    NaN        1      4   \n",
       "...           ...    ...      ...    ...   \n",
       "11051  2020-05-28    NaN        0      1   \n",
       "11052  2020-05-28    NaN        0      0   \n",
       "11053  2020-05-28    1.0        2      4   \n",
       "11054  2020-05-28    NaN        3      4   \n",
       "11055  2020-05-27    NaN        0      1   \n",
       "\n",
       "                                                 caption      brand  \n",
       "0              $PLTR $AAPL what a waste of time today...      Apple  \n",
       "1      $AAPL hoping to get above 130 by Friday! Is th...      Apple  \n",
       "2      SmartOptions® Unusual Activity Alert\\n(Delayed...      Apple  \n",
       "3      More paper hand shake outs on no news. Vaccine...      Apple  \n",
       "4      $AAPL AND.....this is what we call a bear trap...      Apple  \n",
       "...                                                  ...        ...  \n",
       "11051                                       $SBUX 80 EOW  Starbucks  \n",
       "11052  $SBUX can’t lie, this one is a bit scary becau...  Starbucks  \n",
       "11053  $SBUX get ready to get punished bears 😹😹😹😹😹😹😹😹...  Starbucks  \n",
       "11054                                           $SBUX ☕️  Starbucks  \n",
       "11055  Free video with setups for May 28  \"The New No...  Starbucks  \n",
       "\n",
       "[64401 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map Bullish and Bearish to 1 and 0\n",
    "# df_aggregate[\"trend\"] = df_aggregate[\"trend\"].map({\"Bullish\": 1, \"Bearish\": 0})\n",
    "# df_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Programming\\Dashboard_example\\aggregate_stocktwits.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Programming/Dashboard_example/aggregate_stocktwits.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_aggregate[\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df_aggregate[\u001b[39m\"\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "df_aggregate[\"date\"] = pd.to_datetime(df_aggregate[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates = df_aggregate[[\"date\",\"brand\"]].groupby([\"brand\"]).agg([\"min\",\"max\"])\n",
    "# add the multiindex level 0 to the columns names and drop it\n",
    "df_dates.columns = df_dates.columns.get_level_values(0) + \"_\" + df_dates.columns.get_level_values(1)+ \"_stocktwits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_min_stocktwits</th>\n",
       "      <th>date_max_stocktwits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Airbnb</th>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>2021-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>2021-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coca-Cola</th>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>2021-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HM</th>\n",
       "      <td>2018-03-02</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nike</th>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>2021-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pepsi</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>2021-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Starbucks</th>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>2021-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date_min_stocktwits date_max_stocktwits\n",
       "brand                                            \n",
       "Airbnb             2020-12-22          2021-04-13\n",
       "Apple              2021-02-25          2021-03-02\n",
       "Coca-Cola          2020-05-27          2021-03-01\n",
       "HM                 2018-03-02          2021-04-08\n",
       "Nike               2020-04-09          2021-04-25\n",
       "Pepsi              2018-07-12          2021-03-01\n",
       "Starbucks          2020-05-27          2021-03-01"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Pepsi\n",
    "df_aggregate = df_aggregate[df_aggregate[\"brand\"] != \"Pepsi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate.rename(columns={\"date\": \"Date\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>trend</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>caption</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>$PLTR $AAPL what a waste of time today...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>$AAPL hoping to get above 130 by Friday! Is th...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SmartOptions® Unusual Activity Alert\\n(Delayed...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>More paper hand shake outs on no news. Vaccine...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>$AAPL AND.....this is what we call a bear trap...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11051</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>$SBUX 80 EOW</td>\n",
       "      <td>SBUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11052</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>$SBUX can’t lie, this one is a bit scary becau...</td>\n",
       "      <td>SBUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11053</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>$SBUX get ready to get punished bears 😹😹😹😹😹😹😹😹...</td>\n",
       "      <td>SBUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11054</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>$SBUX ☕️</td>\n",
       "      <td>SBUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11055</th>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Free video with setups for May 28  \"The New No...</td>\n",
       "      <td>SBUX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64401 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    trend  replies  likes  \\\n",
       "0     2021-03-02      NaN        1      3   \n",
       "1     2021-03-02      NaN        3      2   \n",
       "2     2021-03-02  Bearish        0      0   \n",
       "3     2021-03-02  Bullish        2     12   \n",
       "4     2021-03-02      NaN        1      4   \n",
       "...          ...      ...      ...    ...   \n",
       "11051 2020-05-28      NaN        0      1   \n",
       "11052 2020-05-28      NaN        0      0   \n",
       "11053 2020-05-28  Bullish        2      4   \n",
       "11054 2020-05-28      NaN        3      4   \n",
       "11055 2020-05-27      NaN        0      1   \n",
       "\n",
       "                                                 caption brand  \n",
       "0              $PLTR $AAPL what a waste of time today...  AAPL  \n",
       "1      $AAPL hoping to get above 130 by Friday! Is th...  AAPL  \n",
       "2      SmartOptions® Unusual Activity Alert\\n(Delayed...  AAPL  \n",
       "3      More paper hand shake outs on no news. Vaccine...  AAPL  \n",
       "4      $AAPL AND.....this is what we call a bear trap...  AAPL  \n",
       "...                                                  ...   ...  \n",
       "11051                                       $SBUX 80 EOW  SBUX  \n",
       "11052  $SBUX can’t lie, this one is a bit scary becau...  SBUX  \n",
       "11053  $SBUX get ready to get punished bears 😹😹😹😹😹😹😹😹...  SBUX  \n",
       "11054                                           $SBUX ☕️  SBUX  \n",
       "11055  Free video with setups for May 28  \"The New No...  SBUX  \n",
       "\n",
       "[64401 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aggregate[\"Date\"] = pd.to_datetime(df_aggregate[\"Date\"])\n",
    "df_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to only include the dates after 2019-07-01\n",
    "df_aggregate = df_aggregate[df_aggregate[\"Date\"] >= \"2019-07-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate.to_csv(\"data/tab2/aggregated_stocktwits.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get overall, daily and weekly trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate = pd.read_csv(\"../tab2/aggregated_stocktwits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>trend</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>caption</th>\n",
       "      <th>brand</th>\n",
       "      <th>bullish</th>\n",
       "      <th>bearish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>$PLTR $AAPL what a waste of time today...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>$AAPL hoping to get above 130 by Friday! Is th...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SmartOptions® Unusual Activity Alert\\n(Delayed...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>More paper hand shake outs on no news. Vaccine...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>$AAPL AND.....this is what we call a bear trap...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60826</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>$SBUX 80 EOW</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60827</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>$SBUX can’t lie, this one is a bit scary becau...</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60828</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>$SBUX get ready to get punished bears 😹😹😹😹😹😹😹😹...</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60829</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>$SBUX ☕️</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60830</th>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Free video with setups for May 28  \"The New No...</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60831 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date    trend  replies  likes  \\\n",
       "0      2021-03-02      NaN        1      3   \n",
       "1      2021-03-02      NaN        3      2   \n",
       "2      2021-03-02  Bearish        0      0   \n",
       "3      2021-03-02  Bullish        2     12   \n",
       "4      2021-03-02      NaN        1      4   \n",
       "...           ...      ...      ...    ...   \n",
       "60826  2020-05-28      NaN        0      1   \n",
       "60827  2020-05-28      NaN        0      0   \n",
       "60828  2020-05-28  Bullish        2      4   \n",
       "60829  2020-05-28      NaN        3      4   \n",
       "60830  2020-05-27      NaN        0      1   \n",
       "\n",
       "                                                 caption      brand  bullish  \\\n",
       "0              $PLTR $AAPL what a waste of time today...      Apple        0   \n",
       "1      $AAPL hoping to get above 130 by Friday! Is th...      Apple        0   \n",
       "2      SmartOptions® Unusual Activity Alert\\n(Delayed...      Apple        0   \n",
       "3      More paper hand shake outs on no news. Vaccine...      Apple        1   \n",
       "4      $AAPL AND.....this is what we call a bear trap...      Apple        0   \n",
       "...                                                  ...        ...      ...   \n",
       "60826                                       $SBUX 80 EOW  Starbucks        0   \n",
       "60827  $SBUX can’t lie, this one is a bit scary becau...  Starbucks        0   \n",
       "60828  $SBUX get ready to get punished bears 😹😹😹😹😹😹😹😹...  Starbucks        1   \n",
       "60829                                           $SBUX ☕️  Starbucks        0   \n",
       "60830  Free video with setups for May 28  \"The New No...  Starbucks        0   \n",
       "\n",
       "       bearish  \n",
       "0            0  \n",
       "1            0  \n",
       "2            1  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "60826        0  \n",
       "60827        0  \n",
       "60828        0  \n",
       "60829        0  \n",
       "60830        0  \n",
       "\n",
       "[60831 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aggregate[\"bullish\"] = (df_aggregate[\"trend\"] == \"Bullish\").astype(int)\n",
    "df_aggregate[\"bearish\"] = (df_aggregate[\"trend\"] == \"Bearish\").astype(int)\n",
    "df_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stocktwits_overall = df_aggregate[[\"brand\",\"trend\",\"Date\"]].groupby([\"brand\",\"trend\"]).count().reset_index()\n",
    "# df_stocktwits_overall.to_csv(\"data/tab2/stocktwits_overall.csv\", index=False)\n",
    "# df_stocktwits_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>Date</th>\n",
       "      <th>bullish</th>\n",
       "      <th>bearish</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2020-12-26</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-02-27</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          brand       Date  bullish  bearish  polarity\n",
       "0        Airbnb 2020-12-22       39       14      0.47\n",
       "1        Airbnb 2020-12-23       59       19      0.51\n",
       "2        Airbnb 2020-12-24       23       13      0.28\n",
       "3        Airbnb 2020-12-25        8        6      0.14\n",
       "4        Airbnb 2020-12-26        8        4      0.33\n",
       "...         ...        ...      ...      ...       ...\n",
       "1765  Starbucks 2021-02-25        9        0      1.00\n",
       "1766  Starbucks 2021-02-26       41        2      0.91\n",
       "1767  Starbucks 2021-02-27        3        1      0.50\n",
       "1768  Starbucks 2021-02-28        3        0      1.00\n",
       "1769  Starbucks 2021-03-01       38        2      0.90\n",
       "\n",
       "[1500 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stocktwits_daily = df_aggregate[[\"brand\",\"bullish\",\"bearish\",\"Date\"]].groupby([\"brand\",\"Date\"]).sum().reset_index()\n",
    "df_stocktwits_daily[\"polarity\"] = (df_stocktwits_daily[\"bullish\"] - df_stocktwits_daily[\"bearish\"])/(df_stocktwits_daily[\"bullish\"] + df_stocktwits_daily[\"bearish\"])\n",
    "df_stocktwits_daily = df_stocktwits_daily.dropna()\n",
    "df_stocktwits_daily[\"polarity\"] = df_stocktwits_daily[\"polarity\"].round(2)\n",
    "df_stocktwits_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stocktwits_daily = df_aggregate[[\"Date\",\"brand\",\"trend\"]].groupby([\"brand\",\"Date\"]).mean().reset_index()\n",
    "# df_stocktwits_daily.fillna(0.5,inplace = True)\n",
    "df_stocktwits_daily.to_csv(\"data/tab2/stocktwits_daily.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate[\"Date\"] = pd.to_datetime(df_aggregate[\"Date\"])\n",
    "df_aggregate[\"week\"] = df_aggregate[\"Date\"].dt.isocalendar().week\n",
    "df_aggregate[\"year\"] = df_aggregate[\"Date\"].dt.year\n",
    "df_aggregate[\"week_year\"] = df_aggregate[\"year\"].astype(str) + \"-\" + df_aggregate[\"week\"].astype(str)\n",
    "df_aggregate[\"week_year\"].replace({\"2019-1\": \"2020-1\",\"2021-53\" : \"2020-53\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks_weeks = pd.read_csv(\"data/tab2/aggregated_stocks_values_weeks.csv\")\n",
    "df_stocks_weeks[\"Date_64\"] = pd.to_datetime(df_stocks_weeks[\"Date\"])\n",
    "df_stocks_weeks[\"week\"] = df_stocks_weeks[\"Date_64\"].dt.isocalendar().week\n",
    "df_stocks_weeks[\"year\"] = df_stocks_weeks[\"Date_64\"].dt.year\n",
    "df_stocks_weeks[\"week_year\"] = df_stocks_weeks[\"year\"].astype(str) + \"-\" + df_stocks_weeks[\"week\"].astype(str)\n",
    "df_stocks_weeks[\"week_year\"].replace({\"2019-1\": \"2020-1\", \"2021-53\" : \"2020-53\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_aggregate[\"Date\"] = pd.to_datetime(df_aggregate[\"Date\"])\n",
    "# df_aggregate[\"week_year\"] = df_aggregate[\"Date\"].dt.strftime(\"%Y-%U\")\n",
    "# df_stocks_weeks[\"Date_64\"] = df_stocks_weeks[\"Date\"].astype(\"datetime64\")\n",
    "# df_stocks_weeks[\"week_year\"] = df_stocks_weeks[\"Date_64\"].dt.strftime(\"%Y-%U\")\n",
    "\n",
    "# # Replace the invalid week\n",
    "# df_stocks_weeks[\"week_year\"].replace({\"2021-00\": \"2020-52\"}, inplace=True)\n",
    "# df_aggregate[\"week_year\"].replace({\"2021-00\": \"2020-52\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>Date</th>\n",
       "      <th>bullish</th>\n",
       "      <th>bearish</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>146</td>\n",
       "      <td>56</td>\n",
       "      <td>44.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>149</td>\n",
       "      <td>86</td>\n",
       "      <td>26.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>199</td>\n",
       "      <td>126</td>\n",
       "      <td>22.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>315</td>\n",
       "      <td>163</td>\n",
       "      <td>31.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>241</td>\n",
       "      <td>82</td>\n",
       "      <td>49.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>116</td>\n",
       "      <td>30</td>\n",
       "      <td>58.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "      <td>79.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>82.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>94.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         brand        Date  bullish  bearish  polarity\n",
       "0       Airbnb  2020-12-21      146       56     44.55\n",
       "1       Airbnb  2020-12-28      149       86     26.81\n",
       "2       Airbnb  2021-01-04      199      126     22.46\n",
       "3       Airbnb  2021-01-11      315      163     31.80\n",
       "4       Airbnb  2021-01-18      241       82     49.23\n",
       "..         ...         ...      ...      ...       ...\n",
       "300  Starbucks  2021-02-01      116       30     58.90\n",
       "301  Starbucks  2021-02-08       78        9     79.31\n",
       "302  Starbucks  2021-02-15       41        4     82.22\n",
       "303  Starbucks  2021-02-22      100        3     94.17\n",
       "304  Starbucks  2021-03-01       38        2     90.00\n",
       "\n",
       "[251 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aggregate[\"date_week\"] = df_aggregate[\"week_year\"].replace(df_stocks_weeks[\"week_year\"].values, df_stocks_weeks[\"Date\"].values)\n",
    "df_aggregate\n",
    "df_stocktwits_weekly = df_aggregate[[\"brand\",\"bullish\",\"bearish\",\"date_week\"]].groupby([\"brand\",\"date_week\"]).sum().reset_index()\n",
    "df_stocktwits_weekly[\"polarity\"] = (df_stocktwits_weekly[\"bullish\"] - df_stocktwits_weekly[\"bearish\"])/(df_stocktwits_weekly[\"bullish\"] + df_stocktwits_weekly[\"bearish\"])\n",
    "df_stocktwits_weekly = df_stocktwits_weekly.dropna()\n",
    "df_stocktwits_weekly[\"polarity\"] = (df_stocktwits_weekly[\"polarity\"]*100).round(2)\n",
    "df_stocktwits_weekly.rename(columns={\"date_week\": \"Date\"}, inplace=True)\n",
    "df_stocktwits_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocktwits_weekly.to_csv(\"data/tab2/stocktwits_weekly.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>Date</th>\n",
       "      <th>bullish</th>\n",
       "      <th>bearish</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>285</td>\n",
       "      <td>137</td>\n",
       "      <td>35.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>1000</td>\n",
       "      <td>422</td>\n",
       "      <td>40.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2021-02</td>\n",
       "      <td>956</td>\n",
       "      <td>178</td>\n",
       "      <td>68.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2021-03</td>\n",
       "      <td>1086</td>\n",
       "      <td>137</td>\n",
       "      <td>77.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2021-04</td>\n",
       "      <td>243</td>\n",
       "      <td>20</td>\n",
       "      <td>84.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2020-11</td>\n",
       "      <td>234</td>\n",
       "      <td>63</td>\n",
       "      <td>57.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>499</td>\n",
       "      <td>42</td>\n",
       "      <td>84.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>421</td>\n",
       "      <td>55</td>\n",
       "      <td>76.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-02</td>\n",
       "      <td>335</td>\n",
       "      <td>46</td>\n",
       "      <td>75.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-03</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        brand     Date  bullish  bearish  polarity\n",
       "0      Airbnb  2020-12      285      137     35.07\n",
       "1      Airbnb  2021-01     1000      422     40.65\n",
       "2      Airbnb  2021-02      956      178     68.61\n",
       "3      Airbnb  2021-03     1086      137     77.60\n",
       "4      Airbnb  2021-04      243       20     84.79\n",
       "..        ...      ...      ...      ...       ...\n",
       "80  Starbucks  2020-11      234       63     57.58\n",
       "81  Starbucks  2020-12      499       42     84.47\n",
       "82  Starbucks  2021-01      421       55     76.89\n",
       "83  Starbucks  2021-02      335       46     75.85\n",
       "84  Starbucks  2021-03       38        2     90.00\n",
       "\n",
       "[69 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aggregate[\"year_month\"] = df_aggregate[\"Date\"].dt.strftime(\"%Y-%m\")\n",
    "df_aggregate\n",
    "df_stocktwits_monthly = df_aggregate[[\"brand\",\"bullish\",\"bearish\",\"year_month\"]].groupby([\"brand\",\"year_month\"]).sum().reset_index()\n",
    "df_stocktwits_monthly[\"polarity\"] = (df_stocktwits_monthly[\"bullish\"] - df_stocktwits_monthly[\"bearish\"])/(df_stocktwits_monthly[\"bullish\"] + df_stocktwits_monthly[\"bearish\"])\n",
    "df_stocktwits_monthly = df_stocktwits_monthly.dropna()\n",
    "df_stocktwits_monthly[\"polarity\"] = (df_stocktwits_monthly[\"polarity\"]*100).round(2)\n",
    "df_stocktwits_monthly.rename(columns={\"year_month\": \"Date\"}, inplace=True)\n",
    "df_stocktwits_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocktwits_monthly.to_csv(\"../tab2/stocktwits_monthly.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get daily, weekly stocktwits count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks_weeks = pd.read_csv(\"data/tab2/aggregated_stocks_values_weeks.csv\")\n",
    "df_aggregate = pd.read_csv(\"data/tab2/aggregated_stocktwits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>Date</th>\n",
       "      <th>stocktwits_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>2020-12-26</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-02-27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1162 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          brand        Date  stocktwits_count\n",
       "0        Airbnb  2020-12-22                97\n",
       "1        Airbnb  2020-12-23               125\n",
       "2        Airbnb  2020-12-24                75\n",
       "3        Airbnb  2020-12-25                18\n",
       "4        Airbnb  2020-12-26                23\n",
       "...         ...         ...               ...\n",
       "1157  Starbucks  2021-02-25                28\n",
       "1158  Starbucks  2021-02-26               117\n",
       "1159  Starbucks  2021-02-27                27\n",
       "1160  Starbucks  2021-02-28                14\n",
       "1161  Starbucks  2021-03-01                99\n",
       "\n",
       "[1162 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stocktwits_daily_count = df_aggregate[[\"Date\",\"brand\",\"replies\"]].groupby([\"brand\",\"Date\"]).count().reset_index()\n",
    "df_stocktwits_daily_count.rename(columns={\"replies\":\"stocktwits_count\"}, inplace=True)\n",
    "df_stocktwits_daily_count.to_csv(\"data/tab2/stocktwits_daily_count.csv\", index=False)\n",
    "df_stocktwits_daily_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52759"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stocktwits_daily_count[\"stocktwits_count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocktwits_daily_count[\"Date\"] = pd.to_datetime(df_stocktwits_daily_count[\"Date\"])\n",
    "df_stocktwits_daily_count[\"week\"] = df_stocktwits_daily_count[\"Date\"].dt.isocalendar().week\n",
    "df_stocktwits_daily_count[\"year\"] = df_stocktwits_daily_count[\"Date\"].dt.year\n",
    "df_stocktwits_daily_count[\"week_year\"] = df_stocktwits_daily_count[\"year\"].astype(str) + \"-\" + df_stocktwits_daily_count[\"week\"].astype(str)\n",
    "df_stocktwits_daily_count[\"week_year\"].replace({\"2019-1\": \"2020-1\",\"2021-53\" : \"2020-53\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks_weeks = pd.read_csv(\"data/tab2/aggregated_stocks_values_weeks.csv\")\n",
    "df_stocks_weeks[\"Date_64\"] = pd.to_datetime(df_stocks_weeks[\"Date\"])\n",
    "df_stocks_weeks[\"week\"] = df_stocks_weeks[\"Date_64\"].dt.isocalendar().week\n",
    "df_stocks_weeks[\"year\"] = df_stocks_weeks[\"Date_64\"].dt.year\n",
    "df_stocks_weeks[\"week_year\"] = df_stocks_weeks[\"year\"].astype(str) + \"-\" + df_stocks_weeks[\"week\"].astype(str)\n",
    "df_stocks_weeks[\"week_year\"].replace({\"2019-1\": \"2020-1\", \"2021-53\" : \"2020-53\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_aggregate[\"Date\"] = pd.to_datetime(df_aggregate[\"Date\"])\n",
    "# df_aggregate[\"week_year\"] = df_aggregate[\"Date\"].dt.strftime(\"%Y-%U\")\n",
    "# df_stocks_weeks[\"Date_64\"] = df_stocks_weeks[\"Date\"].astype(\"datetime64\")\n",
    "# df_stocks_weeks[\"week_year\"] = df_stocks_weeks[\"Date_64\"].dt.strftime(\"%Y-%U\")\n",
    "\n",
    "# # Replace the invalid week\n",
    "# df_stocks_weeks[\"week_year\"].replace({\"2021-00\": \"2020-52\"}, inplace=True)\n",
    "# df_aggregate[\"week_year\"].replace({\"2021-00\": \"2020-52\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocktwits_daily_count[\"date_week\"] = df_stocktwits_daily_count[\"week_year\"].replace(df_stocks_weeks[\"week_year\"].values, df_stocks_weeks[\"Date\"].values)\n",
    "df_stocktwits_weekly = df_stocktwits_daily_count[[\"brand\",\"date_week\",\"stocktwits_count\"]].groupby([\"brand\", \"date_week\"]).sum().reset_index()\n",
    "df_stocktwits_weekly.rename(columns={\"date_week\":\"Date\", \"replies\":\"stocktwits_count\"}, inplace=True)\n",
    "df_stocktwits_weekly.to_csv(\"data/tab2/stocktwits_weekly_count.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd16a1c2e981052eaae61151b9525ae9913f1f0d16bca6b7e7be9e0f29d739d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
